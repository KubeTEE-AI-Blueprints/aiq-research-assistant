general:
  use_uvloop: true
  front_end:
    _type: fastapi
    endpoints:
      - path: /generate_query
        method: POST
        description: Creates the query
        function_name: generate_query
      - path: /generate_summary
        method: POST
        description: Generates the summary
        function_name: generate_summary
      - path: /artifact_qa
        method: POST
        description: Q/A or chat about a previously generated artifact
        function_name: artifact_qa
      - path: /aiqhealth
        method: GET
        description: Health check for the AIQ AIRA service
        function_name: health_check
      - path: /default_collections
        method: GET
        description: Get the default collections
        function_name: default_collections
  telemetry:
    logging:
      console:
        _type: console
        level: DEBUG
    tracing:
      weave:
        _type: weave
        project: "nat-evaluators-test3"

llms:
  # The inst_llm is used for Q&A and report writing and should be an instruct model.
  # The default configuration below is assuming a docker compose deployment of AIRA 
  # that uses local NVIDIA NIM microservices.
  # Update if you are deploying differently or using hosted NVIDIA NIM microservices.
  instruct_llm:
    _type: nim
    model_name: meta/llama-3.3-70b-instruct
    temperature: 0.0
    base_url: https://integrate.api.nvidia.com/v1
    api_key: ${NVIDIA_API_KEY}
  # The reasoning llm is used for report planning and reflection and should be a reasoning model
  # that supports thinking tokens. The default configuration below is used assuming a docker compose
  # deployment of AIRA and RAG with a local NVIDIA NIM microservice for the nemotron model.
  # Update if you are deploying differently or using hosted NVIDIA NIM microservices.
  nemotron:
    _type: nim
    model_name : nvidia/llama-3.3-nemotron-super-49b-v1
    temperature: 0.5
    base_url: https://integrate.api.nvidia.com/v1
    # stream: false
    disable_streaming: false # Disable streaming to prevent truncation issues
    api_key: ${NVIDIA_API_KEY}  # Uncomment this for hosted endpoint
    max_tokens: 5000  
    # top_p: 0.9  # Add top_p parameter for better sampling
    # seed: 42  # Add seed for deterministic results
  eval_llm:
    _type: nim
    model_name: meta/llama-3.1-70b-instruct
    temperature: 0.0
    base_url: https://integrate.api.nvidia.com/v1
    api_key: ${NVIDIA_API_KEY}

  # Mistral is a good model for RAGAS metrics due to the variability it provides as opposed to the llama models
  ragas_llm:
    _type: nim
    model_name: nvdev/mistralai/mixtral-8x22b-instruct-v0.1
    temperature: 0.0
    base_url: https://integrate.api.nvidia.com/v1
    api_key: ${NVIDIA_API_KEY}

functions:
  generate_query:
    _type: generate_queries

  generate_summary:
    _type: generate_summaries
    # update to the IP address of the RAG server if you are not deploying RAG with docker compose (using one of our endpoints for now)
    rag_url: http://10.185.119.221:8081/v1

  artifact_qa:
    _type: artifact_qa
    llm_name: instruct_llm
    # update to the IP address of the RAG server if you are not deploying RAG with docker compose (using one of our endpoints for now)
    rag_url: http://10.185.119.221:8081/v1
    
  health_check:
    _type: health_check

  default_collections:
    _type: default_collections
    collections:
      - name: "Biomedical_Dataset"
        topic: "Biomedical"
        report_organization: "You are a medical researcher who specializes in cystic fibrosis. Create a report analyzing how CFTR modulators can be used to restore CFTR protein functions. Include a 150-200 word abstract and a methods, results, and discussion section. Format your answer in paragraphs. Consider all (and only) relevant data. Give a factual report with cited sources."
      - name: "Financial_Dataset"
        topic: "Financial"
        report_organization: "You are a financial analyst who specializes in financial statement analysis. Write a financial report analyzing the 2023 financial performance of Amazon. Identify trends in revenue growth, net income, and total assets. Discuss how these trends affected Amazon's yearly financial performance for 2023. Your output should be organized into a brief introduction, as many sections as necessary to create a comprehensive report, and a conclusion. Format your answer in paragraphs. Use factual sources such as Amazon's quarterly meeting releases for 2023. Cross analyze the sources to draw original and sound conclusions and explain your reasoning for arriving at conclusions. Do not make any false or unverifiable claims. I want a factual report with cited sources."


workflow:
  _type: aira_evaluator_workflow
  generator:
    _type: full
    verbose: true
    fact_extraction_llm: nvdev/meta/llama-3.1-70b-instruct
    citation_pairing_llm: gpt-4o-20241120 # Configurable LLM for citation pairing


# Evaluation configuration
eval:
  general:
    output_dir: ./.tmp/aiq_aira/
    cleanup: true
    workflow_alias: "tester_for_sean_eci"

    dataset:
      _type: json
      file_path: data/eval_dataset_processed.json
      id_key: id
      structure:
        disable: true
    profiler:
     base_metrics: false  # Disable to prevent runtime metrics errors with --skip_workflow

  evaluators:
    coverage:
      _type: coverage
      llm: eval_llm

    hallucination:
      _type: hallucination 
      llm: eval_llm

    synthesis:
      _type: synthesis
      llm: eval_llm
    
    citation_quality:
      _type: citation_quality
      llm: eval_llm

    rag_accuracy:
      _type: ragas_wrapper  
      metric: AnswerAccuracy
      llm: ragas_llm

    rag_groundedness:
      _type: ragas_wrapper
      metric: ResponseGroundedness
      llm: ragas_llm
      
    rag_relevance:
      _type: ragas_wrapper
      metric: ContextRelevance
      llm: ragas_llm
