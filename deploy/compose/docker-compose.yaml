# SPDX-FileCopyrightText: Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

services:
  aira-instruct-llm:
    container_name: aira-instruct-llm
    image: nvcr.io/nim/meta/llama-3.3-70b-instruct:latest
    runtime: nvidia
    volumes:
    - ${MODEL_DIRECTORY:-./}:/opt/nim/.cache
    user: "${USERID}"
    ports:
    - "8050:8000"
    expose:
    - "8050"
    environment:
      NGC_API_KEY: ${NGC_API_KEY}
    shm_size: 20gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              # RAG uses 0,1 so we assign 2,3 to the LLM
              device_ids: ['${AIRA_LLM_MS_GPU_ID:-2,3}']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python3", "-c", "import requests; requests.get('http://localhost:8000/v1/health/ready')"]
      interval: 30s
      timeout: 20s
      retries: 100
    networks:
      - nvidia-rag
    profiles: ["aira-instruct-llm"]

  aira-backend:
    container_name: aira-backend
    image: nvcr.io/nvidia/blueprint/aira-backend:v1.1.0
    build:
      context: ../../
      dockerfile: deploy/Dockerfile
    entrypoint: "/entrypoint.sh"
    ports:
      - "3838:3838"
    expose:
      - "3838"
    environment:
      TAVILY_API_KEY: ${TAVILY_API_KEY:-this-is-a-test-key}
      AIRA_APPLY_GUARDRAIL: "false"
      OPENAI_API_KEY: ${NVIDIA_API_KEY:-your-nvidia-api-key}
      AIRA_HOSTED_NIMS: ${AIRA_HOSTED_NIMS:-false}
      # Required for rag middleware via fastapi extensions
      RAG_INGEST_URL: ${RAG_INGEST_URL:-http://rag-server:8082/v1}
      # Redis configuration for session management
      REDIS_HOST: ${REDIS_HOST:-aira-redis}
      REDIS_PORT: ${REDIS_PORT:-6380}
      SESSION_TIMEOUT_HOURS: ${SESSION_TIMEOUT_HOURS:-24}
      AIQ_SSA_CLIENT_ID: ${AIQ_SSA_CLIENT_ID:-nvssa-prd-the-client-id}
      AIQ_SSA_CLIENT_SECRET: ${AIQ_SSA_CLIENT_SECRET:-ssa-prod-secret}
      RAG_SERVER_URL: ${RAG_SERVER_URL:-http://rag-server:8081/v1}
      INSTRUCT_LLM_BASE_URL: ${INSTRUCT_LLM_BASE_URL:-http://aira-instruct-llm:8000/v1}
      NEMOTRON_LLM_BASE_URL: ${NEMOTRON_LLM_BASE_URL:-http://nim-llm-ms:8000/v1}

    volumes:
      - ../../configs:/app/configs
    networks:
      - nvidia-rag
    depends_on:
      aira-redis:
        condition: service_healthy
    profiles: ["aira"]

  # Redis for session TTL tracking
  aira-redis:
    image: redis:7-alpine
    container_name: aira-redis
    ports:
      - "6380:6380"
    # Enable persistence: save every 60s if 1+ keys changed, AOF enabled
    # Run Redis on port 6380 internally to avoid conflicts
    command: redis-server --port 6380 --save 60 1 --appendonly yes
    volumes:
      - aira-redis-data:/data
    networks:
      - nvidia-rag
    profiles: ["aira"]
    healthcheck:
      test: ["CMD", "redis-cli", "-p", "6380", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  aira-frontend:
    container_name: aira-frontend
    image: nvcr.io/nvidia/blueprint/aira-frontend:v1.1.0
    ports:
      - "3000:3000"
    expose:
      - "3000"
    networks:
      - nvidia-rag
    environment:
      NVWB_TRIM_PREFIX: true
      INFERENCE_ORIGIN: ${INFERENCE_ORIGIN:-http://aira-backend:3838}
      STARFLEET_CLIENT_ID: ${AIQ_STARFLEET_CLIENT_ID:-starfleet-prd-web-client-id}
      AUTH_PROCESS: ${AUTH_PROCESS:-starfleet}
      # Starfleet Authentication Configuration
      NEXTAUTH_URL: ${NEXTAUTH_URL:-http://localhost:3000}
      STARFLEET_AUTHORIZATION_ENDPOINT: ${STARFLEET_AUTHORIZATION_ENDPOINT:-https://login.nvidia.com/authorize}
      STARFLEET_WELL_KNOWN_URL: ${STARFLEET_WELL_KNOWN_URL:-https://login.nvidia.com/.well-known/openid-configuration}
      STARFLEET_TOKEN_ENDPOINT: ${STARFLEET_TOKEN_ENDPOINT:-https://login.nvidia.com/token}
      STARFLEET_REDIRECT_URI: ${STARFLEET_REDIRECT_URI:-http://localhost:3000/api/auth/callback/nvlogin}
      # Common Configuration
    profiles: ["aira"]

# Use the nvidia-rag network created by the
# RAG docker compose deployment
# If you are deploying RAG separately
# set external to false
networks:
  nvidia-rag:
    external: true
    name: nvidia-rag

# Persistent volumes
volumes:
  aira-redis-data:
